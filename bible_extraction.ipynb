{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in ./americas_nlp/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./americas_nlp/lib/python3.11/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./americas_nlp/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/MT-Project/data/americas_nlp/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Bs\n",
    "\n",
    "quechua_xml = open('Quichua-NT.xml', 'r')\n",
    "quechua_xml = quechua_xml.read()\n",
    "\n",
    "spanish_xml = open('Spanish.xml', 'r')\n",
    "spanish_xml = spanish_xml.read()\n",
    "\n",
    "quechua_soup = Bs(quechua_xml, 'html.parser')\n",
    "spanish_soup = Bs(spanish_xml, 'html.parser')\n",
    "\n",
    "quechua_segs = quechua_soup.find_all(\"seg\")\n",
    "spanish_segs = spanish_soup.find_all(\"seg\")\n",
    "\n",
    "que_data = []\n",
    "spa_data = []\n",
    "for que in quechua_segs:\n",
    "    for spa in spanish_segs:\n",
    "        que_id = que.get(\"id\")\n",
    "        spa_id = spa.get(\"id\")\n",
    "        if que_id == spa_id:\n",
    "            que_data.append(que.text.strip())\n",
    "            spa_data.append(spa.text.strip())\n",
    "\n",
    "\n",
    "with open('parallel-data/extra/bible/bible_quechua.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(que_data))\n",
    "\n",
    "with open('parallel-data/extra/bible/bible_spanish.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(spa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path:  parallel-data/original/jw300\n",
      "Original data size:  125008 125008\n",
      "Actual data size:  121064\n",
      "Data path:  parallel-data/original/dict_misc\n",
      "Original data size:  9000 9000\n",
      "Actual data size:  8998\n",
      "Data path:  parallel-data/original/minedu\n",
      "Original data size:  643 643\n",
      "Actual data size:  643\n",
      "Data path:  parallel-data/extra/bible\n",
      "Original data size:  7935 7935\n",
      "Actual data size:  7935\n",
      "Data path:  parallel-data/extra/bol_const\n",
      "Original data size:  2194 2194\n",
      "Actual data size:  2193\n",
      "Data path:  parallel-data/extra/per_const\n",
      "Original data size:  1277 1277\n",
      "Actual data size:  1276\n",
      "Data path:  parallel-data/extra/lexicon\n",
      "Original data size:  6161 6161\n",
      "Actual data size:  6161\n",
      "Data path:  parallel-data/extra/handbook\n",
      "Original data size:  2297 2298\n",
      "Actual data size:  2296\n",
      "Data path:  parallel-data/extra/web_misc\n",
      "Original data size:  985 985\n",
      "Actual data size:  985\n",
      "Data path:  parallel-data/extra/tatoeba\n",
      "Original data size:  163 163\n",
      "Actual data size:  163\n",
      "Data path:  parallel-data/quz/jw300/\n",
      "Original data size:  136589 136589\n",
      "Actual data size:  131233\n",
      "Data path:  parallel-data/quz/per_const\n",
      "Original data size:  999 999\n",
      "Actual data size:  999\n",
      "Data path:  parallel-data/quz/reglamento\n",
      "Original data size:  287 287\n",
      "Actual data size:  287\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_paths = {\n",
    "    \"jw300\": \"parallel-data/original/jw300\",\n",
    "    \"dict_misc\": \"parallel-data/original/dict_misc\",\n",
    "    \"minedu\": \"parallel-data/original/minedu\",\n",
    "\n",
    "    \"bible\": \"parallel-data/extra/bible\",\n",
    "    \"bol_const\": \"parallel-data/extra/bol_const\",\n",
    "    \"per_const\": \"parallel-data/extra/per_const\",\n",
    "    \"lexicon\": \"parallel-data/extra/lexicon\",\n",
    "    \"handbook\": \"parallel-data/extra/handbook\",\n",
    "    \"web_misc\": \"parallel-data/extra/web_misc\",\n",
    "    \"tatoeba\": \"parallel-data/extra/tatoeba\",\n",
    "\n",
    "    \"quz_jw300\": \"parallel-data/quz/jw300/\",\n",
    "    \"quz_per_const\": \"parallel-data/quz/per_const\",\n",
    "    \"quz_reglamento\": \"parallel-data/quz/reglamento\",\n",
    "}\n",
    "\n",
    "src_lang = \"spanish\"\n",
    "tgt_lang = \"quechua\"\n",
    "for data_code in data_paths:\n",
    "    data_path = data_paths[data_code]\n",
    "    if \"quz\" in data_code:\n",
    "        prefix = \"_\".join(data_code.split(\"_\")[1:])\n",
    "    else:\n",
    "        prefix = data_code\n",
    "    print(\"Data path: \", data_path)\n",
    "    tgt_lang_path = os.path.join(data_path, f\"{prefix}_{tgt_lang}\")\n",
    "    src_lang_path = os.path.join(data_path, f\"{prefix}_{src_lang}\")\n",
    "\n",
    "    tgt_data = open(tgt_lang_path + \".txt\", \"r\").readlines()\n",
    "    src_data = open(src_lang_path + \".txt\", \"r\").readlines()\n",
    "\n",
    "    print(\"Original data size: \", len(tgt_data), len(src_data))\n",
    "\n",
    "    tgt_data = [line.strip() for line in tgt_data]\n",
    "    src_data = [line.strip() for line in src_data]\n",
    "\n",
    "    actual = 0\n",
    "    for tgt_row, src_row in zip(tgt_data, src_data):\n",
    "        if tgt_row and src_row:\n",
    "            actual += 1\n",
    "\n",
    "    print(\"Actual data size: \", actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
